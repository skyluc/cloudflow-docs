= Akka streamlet utilities
:toc:
:toc-title: ON THIS PAGE
:toclevels: 2
:page-supergroup-scala-java: Language

include::ROOT:partial$include.adoc[]

The `cloudflow.akka.util` library contains some predefined `StreamletLogic`{empty}s:

- `HttpServerLogic`
- `SplitterLogic`
- `MergeLogic`

The following sections describe how you implement stream processing logic with these utilities.

== HttpServerLogic

=== Use case

An `HttpServerLogic` can be used to handle HTTP requests and store the received data into an outlet.
You need to extend your streamlet from `AkkaServerStreamlet`
so that Cloudflow will expose an HTTP endpoint in Kubernetes.
The `HttpServerLogic` typically unmarshalls incoming HTTP requests as they arrive and stores the data in the outlet.
Http requests that are attempted while the `HttpServerLogic` is not running will result in a 503 response.

=== Examples

The `HttpServerLogic` defines an abstract method for the user to supply the processing logic, an HTTP route:

[source,scala]
----
def route(sinkRef: WritableSinkRef[Out]): Route
----

The `HttpServerLogic` object has default implementations of the `HttpServerLogic`, which support some pre-baked routes:

* the `default` method creates a `HttpServerLogic` that handles PUT and POST requests, where the data is read from the entity body.
* the `defaultStreaming` method creates a `HttpServerLogic` that handles streaming HTTP requests, where the data is read from the entity body as a framed stream.

=== Handle PUT / POST requests by default

The code snippet below shows an example of an `HttpServerLogic` using the `defaultLogic`:

[.tabset]
Scala::
+
In Scala: 
+
* The `HttpServerLogic` requires an implicit `akka.http.scaladsl.marshalling.FromByteStringUnmarshaller[Out]` to unmarshal the entity body into the data that you want to write to the outlet. (`FromByteStringUnmarshaller[T]` is an alias for `Unmarshaller[ByteString, T]`)
+
* An `HttpServerLogic` can only be used in combination with an `AkkaServerStreamlet`. The `HttpServerLogic.default` method requires a `Server` argument (this also applies to the `HttpServerLogic.defaultStreaming` method and the `HttpServerLogic` constructor, you cannot construct it without it). The `AkkaServerStreamlet` implements `Server`, so you can just pass `this` to it from inside the streamlet, as you can see in the snippet below.
+
* In the example below, the `SensorDataJsonSupport` object defines implicit spray-json JSON formats for the `SensorData` type.
+
[source,scala]
----
include::version1@docexamples:ROOT:example$sensor-data-scala/src/main/scala/sensordata/SensorDataHttpIngress.scala[]
----

Java::
+
In Java, the `akka.http.javadsl.unmarshalling.Unmarshaller<ByteString, T>` is an argument to the constructor. A Jackson `Unmarshaller<ByteString, Out>` is created for the `SensorData` class, using the `Jackson.byteStringUnmarshaller` method, as shown below
+
[source,java]
----
include::ROOT:example$sensor-data-java/src/main/java/sensordata/SensorDataIngress.java[]
----


=== Handle streamed HTTP entities

The `defaultStreaming` requires an implicit `FromByteStringUnmarshaller[Out]` and an `EntityStreamingSupport`.

[.tabset]
Scala::
+
The Scala example below shows: 
+
* How to use the `defaultStreaming` method to unmarshal a JSON stream and write the unmarshalled data to the outlet. It provides a `EntityStreamingSupport.json()` to read the JSON stream. The `defaultStreamingLogic` uses this to read JSON from the request entity.
+
* The `SensorDataJsonSupport` in the example provides implicit spray-json JSON `Formats` to unmarshal the JSON elements in the stream.
+
* The `akka.http.scaladsl.marshallers.sprayjson.SprayJsonSupport` object implicitly provides a `FromByteStringUnmarshaller` based on the formats in the `SensorDataJsonSupport` object.
+
[source,scala]
----
include::ROOT:example$sensor-data-scala/src/main/scala/sensordata/SensorDataStreamingIngress.scala[]
----

Java::
+
The Java example below shows how to use the `defaultStreaming` in a similar manner:
+
[source,java]
----
include::ROOT:example$sensor-data-java/src/main/java/sensordata/SensorDataStreamingIngress.java[]
----

=== Define a custom Route

If you want to provide your own `akka-http` Route, override the `route` method.
The `route` method provides a `sinkRef` argument which you can use to write to the outlet.

[source,scala]
----
override def createLogic = new HttpServerLogic(this, outlet) {
  def route(sinkRef: WritableSinkRef[Out]): Route = {
    put {
      entity(as[Data]) { data ⇒
        onSuccess(sinkRef.write(data)) { _ ⇒
          complete(StatusCodes.OK)
        }
      }
    }
  }
}
----

The above Scala example creates a route that will handle put requests where the entity contains `Data`, which is written to the outlet using the `WritableSinkRef`.

== SplitterLogic

=== Use case

A `SplitterLogic` can be used to split a stream in two, writing elements to one of two outlets.
Every element from the outlet will be processed through a `FlowWithOffsetContext`, which provides at-least-once semantics.

=== Example

The `SplitterLogic` defines an abstract `flow` method for the user to supply a `FlowWithOffsetContext[I, Either[L, R]]`.
The Java version of `Splitter` uses an `Either` type that is bundled with cloudflow as `cloudflow.akka.javadsl.util.Either`.

The examples below shows a `Splitter` that validates metrics and splits the stream into valid and invalid metrics, which are written respectively to the `valid` and `invalid` outlets:

[.tabset]
Scala::
+
[source,scala]
----
include::ROOT:example$sensor-data-scala/src/main/scala/sensordata/MetricsValidation.scala[]
----

Java::
+
[source,java]
----
include::ROOT:example$sensor-data-java/src/main/java/sensordata/MetricsValidation.java[]
----

== MergeLogic

=== Use case

A `MergeLogic` can be used to merge two or more inlets into one outlet.

Elements from all inlets will be processed with at-least-once semantics. The elements will be processed in semi-random order and with equal priority for all inlets.

=== Example

The examples below shows a `Merge` configured to combine elements from two inlets of the type `Metric` into one outlet of the same type.

[.tabset]
Scala::
+
[source,scala]
----
object MetricMerge extends AkkaStreamlet {

  val in0 = AvroInlet[Metric]("in-0")
  val in1 = AvroInlet[Metric]("in-1")
  val out = AvroOutlet[Metric]("out", m ⇒ m.deviceId.toString + m.timestamp.toString)

  final override val shape = StreamletShape.withInlets(in0, in1).withOutlets(out)

  override final def createLogic = new MergeLogic(Vector(in0, in1), out)
}

object MetricsMerge extends Merge[Metric](5)
----

Java::
+
[source,java]
----
class TestMerger extends AkkaStreamlet {
    AvroInlet<Data> inlet1 = AvroInlet.<Data>create("in-0", Data.class);
    AvroInlet<Data> inlet2 = AvroInlet.<Data>create("in-1", Data.class);
    AvroOutlet<Data> outlet = AvroOutlet.<Data>create("out",  d -> d.name(), Data.class);

    public StreamletShape shape() {
      return StreamletShape.createWithInlets(inlet1, inlet2).withOutlets(outlet);
    }
    public MergeLogic createLogic() {
      List<CodecInlet<Data>> inlets = new ArrayList<CodecInlet<Data>>();
      inlets.add(inlet1);
      inlets.add(inlet2);
      return new MergeLogic(inlets, outlet, getStreamletContext());
    }
}
----
